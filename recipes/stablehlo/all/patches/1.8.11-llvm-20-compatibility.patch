diff --git a/stablehlo/conversions/tosa/transforms/StablehloLegalizeToTosa.pdll b/stablehlo/conversions/tosa/transforms/StablehloLegalizeToTosa.pdll
--- a/stablehlo/conversions/tosa/transforms/StablehloLegalizeToTosa.pdll
+++ b/stablehlo/conversions/tosa/transforms/StablehloLegalizeToTosa.pdll
@@ -16,6 +16,31 @@
 #include "stablehlo/dialect/StablehloOps.td"
 
 // Helper functions.
+Rewrite changeElementTypeToI1(type: Type) -> Type [{
+  auto tensorType = llvm::cast<mlir::RankedTensorType>(type);
+  return RankedTensorType::get(tensorType.getShape(), rewriter.getI1Type());
+}];
+
+Rewrite getScalarInt8Tensor() -> Type [{
+  return RankedTensorType::get({1}, rewriter.getI8Type());
+}];
+
+Rewrite zerosLike(op: Op, type: Type) -> Op [{
+  auto elementType = llvm::cast<mlir::TensorType>(type).getElementType();
+  llvm::SmallVector<mlir::Attribute, 4> outputValue;
+
+  if (elementType.isF16() || elementType.isF32() || elementType.isBF16()) {
+    outputValue.push_back(rewriter.getFloatAttr(elementType, 0));
+  } else {
+    outputValue.push_back(rewriter.getIntegerAttr(elementType, 0));
+  }
+
+  return rewriter.create<mlir::tosa::ConstOp>(
+      op->getLoc(), type,
+      mlir::DenseElementsAttr::get(
+        llvm::cast<mlir::ShapedType>(type), outputValue));
+}];
+
 Rewrite onesLike(op: Op, type: Type) -> Op [{
   auto elementType = llvm::cast<mlir::TensorType>(type).getElementType();
   llvm::SmallVector<mlir::Attribute, 4> outputValue;
@@ -47,11 +72,6 @@
         llvm::cast<mlir::ShapedType>(type), outputValue));
 }];
 
-Rewrite changeElementTypeToI1(type: Type) -> Type [{
-  auto tensorType = llvm::cast<mlir::RankedTensorType>(type);
-  return RankedTensorType::get(tensorType.getShape(), rewriter.getI1Type());
-}];
-
 // Nullary ops.
 Pattern =>
   replace op<stablehlo.constant> {value = input: Attr<_: Tosa_Tensor>}
@@ -134,10 +154,16 @@
   replace op<stablehlo.minimum>(input0 : Value<_: Tosa_Tensor>,
                            input1 : Value<_: Tosa_Tensor>)
      with op<tosa.minimum>(input0, input1);
-Pattern =>
-  replace op<stablehlo.multiply>(input0 : Value<_: Tosa_Tensor>,
-                            input1 : Value<_: Tosa_Tensor>)
-     with op<tosa.mul>(input0, input1) {shift = attr<"0 : i8">};
+Pattern {
+  let root = op<stablehlo.multiply>(input0 : Value<inputType: Tosa_Tensor>,
+                            input1 : Value<_: Tosa_Tensor>);
+  rewrite root with {
+    let typei8 = getScalarInt8Tensor();
+    let zeros = zerosLike(root, typei8);
+    let mulResult = op<tosa.mul>(input0, input1, zeros) -> (inputType);
+    replace root with mulResult;
+  };
+}
 Pattern =>
   replace op<stablehlo.or>(input0 : Value<_: Tosa_Tensor>,
                       input1 : Value<_: Tosa_Tensor>)
diff --git a/stablehlo/reference/Types.cpp b/stablehlo/reference/Types.cpp
--- a/stablehlo/reference/Types.cpp
+++ b/stablehlo/reference/Types.cpp
@@ -48,13 +48,12 @@
 }
 
 bool isSupportedFloatType(Type type) {
-  return type.isFloat4E2M1FN() || type.isFloat6E2M3FN() ||
-         type.isFloat6E3M2FN() || type.isFloat8E3M4() ||
-         type.isFloat8E4M3B11FNUZ() || type.isFloat8E4M3() ||
-         type.isFloat8E4M3FN() || type.isFloat8E4M3FNUZ() ||
-         type.isFloat8E5M2() || type.isFloat8E5M2FNUZ() ||
-         type.isFloat8E8M0FNU() || type.isF16() || type.isBF16() ||
-         type.isF32() || type.isF64();
+  return llvm::isa<
+      mlir::Float4E2M1FNType, mlir::Float6E2M3FNType, mlir::Float6E3M2FNType,
+      mlir::Float8E3M4Type, mlir::Float8E4M3B11FNUZType, mlir::Float8E4M3Type,
+      mlir::Float8E4M3FNType, mlir::Float8E4M3FNUZType, mlir::Float8E5M2Type,
+      mlir::Float8E5M2FNUZType, mlir::Float8E8M0FNUType, mlir::Float16Type,
+      mlir::BFloat16Type, mlir::Float32Type, mlir::Float64Type>(type);
 }
 
 bool isSupportedComplexType(Type type) {
